---
# [int] (optional) Env seed (auto-generated if blank)
seed: ~

# [string] (optional) Unique ID of this run (auto-generated if blank)
run_id: ~

# [string] (optional) Continue training of a previously trained model
model_load_file: ~

# [string] Directory template to save the trained model, metadata and
# tensorboard logs. If the template contains {run_id} or {seed} placeholders,
# they will be replaced with the corresponding runtime values.
out_dir_template: "data/PPO-{run_id}"

# [bool] Log tensorboard data
log_tensorboard: true

# [int] Training duration (set to a minimum of 10-20M for PPO)
total_timesteps: 100_000

# [int] (optional) Force env termination on the Nth step of an episode
max_episode_steps: 5000

# [int] Number of times the model will be saved during training
# Example: 5 means save at 20%, 40%, 60%, 80% and 100% progress
n_checkpoints: 5

# PPO algorithm parameters (used only if model_load_file is blank)
# https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html
learner_kwargs:
  policy: "MlpPolicy"
  use_sde: false
  sde_sample_freq: 4
  n_steps: 2048
  batch_size: 32
  n_epochs: 10
  gamma: 0.9
  gae_lambda: 0.98
  clip_range: 0.4
  normalize_advantage: true
  ent_coef: 0.001
  vf_coef: 0.5
  max_grad_norm: 3

# (string) Schedule for the learning_rate as a function of the progress remaining.
# Format: const_V0 | lin_decay_V0_V1_F | exp_decay_V0_V1_F_N
learner_lr_schedule: "const_0.001"

# Env parameters. __include__ loads from config/env.yml; keys here override.
env_kwargs:
  __include__: "config/env.yml"
  frames_per_step: 4
  reduced_action_set: false

# List of gym wrappers to use for the env
env_wrappers: []
