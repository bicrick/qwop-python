# DQNfD Stage 1: Warm-up with Demonstrations
# Brought over from qwop-wr/config
#
# Full DQNfD pipeline requires EQRDQN + demo injection (qwop-wr has this).
# This config uses QRDQN with Stage 1 hyperparameters as reference.
# To run true DQNfD: use --resume-from data/QRDQN-PROVEN-<run_id>/model.zip
#
# Expected: ~10M steps. Goal: maintain success rate with expert guidance.

algorithm: QRDQN
total_timesteps: 10_000_000
n_envs: 1  # QRDQN/DQN in SB3 typically uses n_envs=1
max_episode_steps: 1000

# Load PROVEN weights: qwop-python train -c config/train_dqnfd_stage1.yml --resume-from data/QRDQN-PROVEN-k3jlgned/model.zip
# model_load_file: "data/QRDQN-PROVEN-k3jlgned/model.zip"

# DQNfD: inject expert demonstrations during training
# Run qwop-python collect_demos first to generate the .npz file
demo_file: "data/demonstrations/qrdqn_proven_demos.npz"
demo_injection_ratio: 0.5

env_kwargs:
  frames_per_step: 4
  reduced_action_set: true
  failure_cost: 10.0
  success_reward: 50.0
  time_cost_mult: 10.0

learner_kwargs:
  device: "auto"
  buffer_size: 300000
  learning_starts: 10000
  batch_size: 64
  tau: 1.0
  gamma: 0.997
  train_freq: 4
  gradient_steps: 1
  target_update_interval: 512
  exploration_fraction: 0.3
  exploration_initial_eps: 0.1
  exploration_final_eps: 0.01
  learning_rate: 0.001
  policy_kwargs:
    net_arch: [256, 128]

save_freq: 200_000
checkpoint_dir: data/checkpoints
model_dir: data/models

log_dir: data/logs
tensorboard: true
user_metrics_log_interval: 1
